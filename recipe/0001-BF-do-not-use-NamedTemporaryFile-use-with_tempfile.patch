From 4d4c72a075fe7950f6ac04c139b3a9f493aae23e Mon Sep 17 00:00:00 2001
From: Yaroslav Halchenko <debian@onerussian.com>
Date: Thu, 2 Nov 2017 16:33:36 -0400
Subject: [PATCH] BF: do not use NamedTemporaryFile - use @with_tempfile

We were committing a crime of opening a file with NamedTemporaryFile
and then just using the name while writing into it.
Poor windows does not tollerate that well
---
 mvpa2/tests/test_hdf5.py     | 112 ++++++++++++++++++++++---------------------
 mvpa2/tests/test_hdf5_clf.py |  13 +++--
 2 files changed, 64 insertions(+), 61 deletions(-)

diff --git a/mvpa2/tests/test_hdf5.py b/mvpa2/tests/test_hdf5.py
index 5faecac8..bfacdd9a 100644
--- a/mvpa2/tests/test_hdf5.py
+++ b/mvpa2/tests/test_hdf5.py
@@ -107,43 +107,44 @@ def test_matfile_v73_compat():
     assert_array_equal(mat['y'], np.array([(1,0,1)], dtype='uint8').T)
 
 
-def test_directaccess():
-    f = tempfile.NamedTemporaryFile()
-    h5save(f.name, 'test')
-    assert_equal(h5load(f.name), 'test')
-    f.close()
-    f = tempfile.NamedTemporaryFile()
-    h5save(f.name, datasets['uni4medium'])
-    assert_array_equal(h5load(f.name).samples,
+@with_tempfile()
+def test_directaccess(fname):
+    h5save(fname, 'test')
+    assert_equal(h5load(fname), 'test')
+    h5save(fname, datasets['uni4medium'])
+    assert_array_equal(h5load(fname).samples,
                        datasets['uni4medium'].samples)
 
-def test_function_ptrs():
+@with_tempfile()
+def test_function_ptrs(fname):
     skip_if_no_external('nibabel')
     ds = load_example_fmri_dataset()
     # add a mapper with a function ptr inside
     ds = ds.get_mapped(mean_sample())
-    f = tempfile.NamedTemporaryFile()
-    h5save(f.name, ds)
-    ds_loaded = h5load(f.name)
+    h5save(fname, ds)
+    ds_loaded = h5load(fname)
     fresh = load_example_fmri_dataset().O
     # check that the reconstruction function pointer in the FxMapper points
     # to the right one
     assert_array_equal(ds_loaded.a.mapper.forward(fresh),
                        ds.samples)
 
-def test_various_special_cases():
+
+@with_tempfile()
+def test_various_special_cases(fname):
     # 0d object ndarray
-    f = tempfile.NamedTemporaryFile()
     a = np.array(0, dtype=object)
-    h5save(f.name, a)
-    a_ = h5load(f.name)
+    h5save(fname, a)
+    a_ = h5load(fname)
     ok_(a == a_)
     # slice
-    h5save(f.name, slice(2,5,3))
-    sl = h5load(f.name)
+    h5save(fname, slice(2,5,3))
+    sl = h5load(fname)
     ok_(sl == slice(2,5,3))
 
-def test_class_oldstyle():
+
+@with_tempfile()
+def test_class_oldstyle(fname):
     # AttributeError: CustomOld instance has no attribute '__reduce__'
 
     # old style classes do not define reduce -- sure thing we might
@@ -151,38 +152,41 @@ def test_class_oldstyle():
     # exception should be thrown
     co = CustomOldStyle()
     co.v = 1
-    f = tempfile.NamedTemporaryFile()
-    assert_raises(HDF5ConversionError, save, co, f.name, compression='gzip')
+    assert_raises(HDF5ConversionError, save, co, fname, compression='gzip')
 
-def test_locally_defined_class():
+
+@with_tempfile()
+def test_locally_defined_class(fname):
     # cannot store locally defined classes
     class Custom(object):
         pass
     c = Custom()
-    f = tempfile.NamedTemporaryFile()
-    assert_raises(HDF5ConversionError, h5save, f.name, c, compression='gzip')
+    assert_raises(HDF5ConversionError, h5save, fname, c, compression='gzip')
+
 
-def test_dataset_without_chunks():
+@with_tempfile()
+def test_dataset_without_chunks(fname):
     #  ValueError: All chunk dimensions must be positive (Invalid arguments to routine: Out of range)
     # MH: This is not about Dataset chunks, but about an empty samples array
-    f = tempfile.NamedTemporaryFile()
     ds = AttrDataset([8], a=dict(custom=1))
-    save(ds, f.name, compression='gzip')
-    ds_loaded = h5load(f.name)
+    save(ds, fname, compression='gzip')
+    ds_loaded = h5load(fname)
     ok_(ds_loaded.a.custom == ds.a.custom)
 
-def test_recursion():
+
+@with_tempfile()
+def test_recursion(fname):
     obj = range(2)
     obj.append(HDFDemo())
     obj.append(obj)
-    f = tempfile.NamedTemporaryFile()
-    h5save(f.name, obj)
-    lobj = h5load(f.name)
+    h5save(fname, obj)
+    lobj = h5load(fname)
     assert_equal(obj[:2], lobj[:2])
     assert_equal(type(obj[2]), type(lobj[2]))
     ok_(obj[3] is obj)
     ok_(lobj[3] is lobj)
 
+
 @with_tempfile()
 def test_h5save_mkdir(dirname):
     # create deeper directory name
@@ -204,33 +208,35 @@ def test_h5save_mkdir(dirname):
     finally:
         os.chdir(cwd)
 
-def test_state_cycle_with_custom_reduce():
+@with_tempfile()
+def test_state_cycle_with_custom_reduce(fname):
     # BoxcarMapper has a custom __reduce__ implementation . The 'space'
     # setting will only survive a svae/load cycle if the state is correctly
     # handle for custom reduce iplementations.
     bm = BoxcarMapper([0], 1, space='boxy')
-    f = tempfile.NamedTemporaryFile()
-    h5save(f.name, bm)
-    bm_rl = h5load(f.name)
+    h5save(fname, bm)
+    bm_rl = h5load(fname)
     assert_equal(bm_rl.get_space(), 'boxy')
 
-def test_store_metaclass_types():
-    f = tempfile.NamedTemporaryFile()
+
+@with_tempfile()
+def test_store_metaclass_types(fname):
     from mvpa2.kernels.base import Kernel
     allowedtype=Kernel
-    h5save(f.name, allowedtype)
-    lkrn = h5load(f.name)
+    h5save(fname, allowedtype)
+    lkrn = h5load(fname)
     assert_equal(lkrn, Kernel)
     assert_equal(lkrn.__metaclass__, Kernel.__metaclass__)
 
-def test_state_setter_getter():
+
+@with_tempfile()
+def test_state_setter_getter(fname):
     # make sure the presence of custom __setstate__, __getstate__ methods
     # is honored -- numpy's RNGs have it
     from numpy.random.mtrand import RandomState
-    f = tempfile.NamedTemporaryFile()
     r = RandomState()
-    h5save(f.name, r)
-    rl = h5load(f.name)
+    h5save(fname, r)
+    rl = h5load(fname)
     rl_state = rl.get_state()
     for i, v in enumerate(r.get_state()):
         assert_array_equal(v, rl_state[i])
@@ -251,7 +257,8 @@ def test_state_setter_getter():
              dtype=object),
     np.array([], dtype='int64'),
     ))
-def test_save_load_object_dtype_ds(obj=None):
+@with_tempfile()
+def test_save_load_object_dtype_ds(fname, obj=None):
     """Test saving of custom object ndarray (GH #84)
     """
     aobjf = np.asanyarray(obj).flatten()
@@ -259,11 +266,8 @@ def test_save_load_object_dtype_ds(obj=None):
     if not aobjf.size and externals.versions['hdf5'] < '1.8.7':
         raise SkipTest("Versions of hdf5 before 1.8.7 have problems with empty arrays")
 
-    # print obj, obj.shape
-    f = tempfile.NamedTemporaryFile()
-
     # save/reload
-    obj_ = saveload(obj, f.name)
+    obj_ = saveload(obj, fname)
 
     # and compare
     # neh -- not versatile enough
@@ -331,19 +335,18 @@ _numpy_objs += [
 ]
 
 @sweepargs(obj=_python_objs + _numpy_objs)
-def test_save_load_python_objs(obj):
+@with_tempfile()
+def test_save_load_python_objs(fname, obj):
     """Test saving objects of various types
     """
     # print obj, obj.shape
-    f = tempfile.NamedTemporaryFile()
-
     # save/reload
     try:
-        h5save(f.name, obj)
+        h5save(fname, obj)
     except Exception as e:
         raise AssertionError("Failed to h5save %s: %s" % (safe_str(obj), e))
     try:
-        obj_ = h5load(f.name)
+        obj_ = h5load(fname)
     except Exception as e:
         raise AssertionError("Failed to h5load %s: %s" % (safe_str(obj), e))
 
@@ -383,6 +386,7 @@ _nested_l = [2, None]
 _nested_l[1] = [{3: 4}, _nested_l, None]
 _nested_l[1][2] = ['crap', _nested_l]   # 3rd level of nastiness
 
+
 @sweepargs(obj=[_nested_d, _nested_l])
 @sweepargs(backend=['hdf5', 'pickle'])
 @with_tempfile()
diff --git a/mvpa2/tests/test_hdf5_clf.py b/mvpa2/tests/test_hdf5_clf.py
index 24f61714..02ed210f 100644
--- a/mvpa2/tests/test_hdf5_clf.py
+++ b/mvpa2/tests/test_hdf5_clf.py
@@ -30,23 +30,22 @@ from mvpa2.base.hdf5 import h5save, h5load, obj2hdf
 
 
 @sweepargs(lrn=clfswh[:] + regrswh[:])
-def test_h5py_clfs(lrn):
+@with_tempfile()
+def test_h5py_clfs(fname, lrn):
     # lets simply clone it so we could make its all states on
     lrn = lrn.clone()
     # Lets enable all the states
     lrn.ca.enable('all')
 
-    f = tempfile.NamedTemporaryFile()
-
     # Store/reload untrained learner
     try:
-        h5save(f.name, lrn)
+        h5save(fname, lrn)
     except Exception, e:
         raise AssertionError, \
               "Failed to store due to %r" % (e,)
 
     try:
-        lrn_ = h5load(f.name)
+        lrn_ = h5load(fname)
         pass
     except Exception, e:
         raise AssertionError, \
@@ -78,14 +77,14 @@ def test_h5py_clfs(lrn):
 
     # now lets store/reload the trained one
     try:
-        h5save(f.name, lrn_)
+        h5save(fname, lrn_)
     except Exception, e:
         raise AssertionError, \
               "Failed to store trained lrn due to %r" % (e,)
 
     # This lrn__ is doubly stored/loaded ;-)
     try:
-        lrn__ = h5load(f.name)
+        lrn__ = h5load(fname)
     except Exception, e:
         raise AssertionError, \
               "Failed to load trained lrn due to %r" % (e,)
-- 
2.15.0

